{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solvers ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will investigate the effects of different `solvers` on `LogisticRegression` models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Run the code below to import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.47</td>\n",
       "      <td>5.97</td>\n",
       "      <td>7.36</td>\n",
       "      <td>10.17</td>\n",
       "      <td>6.84</td>\n",
       "      <td>9.15</td>\n",
       "      <td>9.78</td>\n",
       "      <td>9.52</td>\n",
       "      <td>10.34</td>\n",
       "      <td>8.80</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.05</td>\n",
       "      <td>8.84</td>\n",
       "      <td>9.76</td>\n",
       "      <td>8.38</td>\n",
       "      <td>10.15</td>\n",
       "      <td>6.91</td>\n",
       "      <td>9.70</td>\n",
       "      <td>9.01</td>\n",
       "      <td>9.23</td>\n",
       "      <td>8.80</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.59</td>\n",
       "      <td>10.71</td>\n",
       "      <td>10.84</td>\n",
       "      <td>10.97</td>\n",
       "      <td>9.03</td>\n",
       "      <td>10.42</td>\n",
       "      <td>11.46</td>\n",
       "      <td>11.25</td>\n",
       "      <td>11.34</td>\n",
       "      <td>9.06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.32</td>\n",
       "      <td>9.65</td>\n",
       "      <td>7.87</td>\n",
       "      <td>10.92</td>\n",
       "      <td>6.97</td>\n",
       "      <td>11.07</td>\n",
       "      <td>10.66</td>\n",
       "      <td>8.89</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.12</td>\n",
       "      <td>13.44</td>\n",
       "      <td>10.35</td>\n",
       "      <td>9.95</td>\n",
       "      <td>11.09</td>\n",
       "      <td>9.38</td>\n",
       "      <td>10.22</td>\n",
       "      <td>9.04</td>\n",
       "      <td>7.68</td>\n",
       "      <td>11.38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0           9.47              5.97         7.36           10.17       6.84   \n",
       "1          10.05              8.84         9.76            8.38      10.15   \n",
       "2          10.59             10.71        10.84           10.97       9.03   \n",
       "3          11.00              8.44         8.32            9.65       7.87   \n",
       "4          12.12             13.44        10.35            9.95      11.09   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density  sulphates  alcohol  \\\n",
       "0                 9.15                  9.78     9.52      10.34     8.80   \n",
       "1                 6.91                  9.70     9.01       9.23     8.80   \n",
       "2                10.42                 11.46    11.25      11.34     9.06   \n",
       "3                10.92                  6.97    11.07      10.66     8.89   \n",
       "4                 9.38                 10.22     9.04       7.68    11.38   \n",
       "\n",
       "   quality rating  \n",
       "0               6  \n",
       "1               7  \n",
       "2               4  \n",
       "3               8  \n",
       "4               3  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/04-Under-the-Hood/solvers_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset consists of different wines üç∑\n",
    "- The features describe different properties of the wines \n",
    "- The target üéØ is a quality rating given by an expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Target engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to transform the ratings into a binary target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá How many observations are there for each rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10    10143\n",
      "5     10124\n",
      "1     10090\n",
      "2     10030\n",
      "8      9977\n",
      "6      9961\n",
      "9      9955\n",
      "7      9954\n",
      "4      9928\n",
      "3      9838\n",
      "Name: quality rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_ratings = df['quality rating'].value_counts()\n",
    "print(count_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create `y` by transforming the target into a binary classification task where quality ratings below 6 are bad [0], and ratings of 6 and above are good [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: quality rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_binary = df['quality rating'].apply(lambda x: 1 if x >= 6 else 0)\n",
    "print(y_binary.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Check the class balance of the new binary target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.5001\n",
      "1    0.4999\n",
      "Name: quality rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_balance = y_binary.value_counts(normalize=True)\n",
    "print(class_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create your `X` by normalising the features. This will allow for fair comparison of different solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0       0.531348          0.285244     0.265966        0.504968   0.229879   \n",
      "1       0.576803          0.420113     0.459984        0.343270   0.412348   \n",
      "2       0.619122          0.507989     0.547292        0.577236   0.350606   \n",
      "3       0.651254          0.401316     0.343573        0.457995   0.286659   \n",
      "4       0.739028          0.636278     0.507680        0.485095   0.464168   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide   density  sulphates   alcohol  \n",
      "0             0.363248              0.451878  0.432173   0.557503  0.413523  \n",
      "1             0.123932              0.442488  0.370948   0.435926  0.413523  \n",
      "2             0.498932              0.649061  0.639856   0.667032  0.432028  \n",
      "3             0.552350              0.122066  0.618247   0.592552  0.419929  \n",
      "4             0.387821              0.503521  0.374550   0.266156  0.597153  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "features = df.iloc[:, :-1]\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(features)\n",
    "X = pd.DataFrame(X_normalized, columns=features.columns)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LogisticRegression solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Logistic Regression models can be optimized using different **solvers**. Make a comparison of the available solvers':\n",
    "- Fit time - which solver is **the fastest**?\n",
    "- Precision - **how different** are their respective precision scores?\n",
    "\n",
    "Available solvers for Logistic Regression are `['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']`\n",
    " \n",
    "For more information on these 5 solvers, check out [this Stack Overflow thread](https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newton-cg': 0.17789006233215332, 'lbfgs': 0.1926288604736328, 'liblinear': 0.14224696159362793, 'sag': 0.3018460273742676, 'saga': 0.6096131801605225}\n",
      "{'newton-cg': 0.8779303648217506, 'lbfgs': 0.8779303648217506, 'liblinear': 0.8784722222222222, 'sag': 0.8778085991678225, 'saga': 0.8779303648217506}\n",
      "liblinear\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=42)\n",
    "\n",
    "# List of solvers to be compared\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "fit_times = {}\n",
    "precision_scores = {}\n",
    "\n",
    "for solver in solvers:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # create train model\n",
    "    model = LogisticRegression(solver=solver, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # training time compute\n",
    "    fit_times[solver] = time.time() - start_time\n",
    "\n",
    "    # predict and compute precision\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision_scores[solver] = precision_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "# find fastest solver\n",
    "fastest_solver = min(fit_times, key=fit_times.get)\n",
    "\n",
    "print(fit_times)\n",
    "print(precision_scores)\n",
    "print(fastest_solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>‚ÑπÔ∏è Click here for our interpretation</summary>\n",
    "\n",
    "All solvers should produce similar precision scores because our cost-function is \"easy\" enough to have a global minimum which is found by all 5 solvers. For very complex cost-functions such as in Deep Learning, different solvers may stopping at different values of the loss function.\n",
    "\n",
    "**The wine dataset**\n",
    "    \n",
    "If you check feature importance with sklearn's <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html\">permutation_importance</a> on the current dataset, you'll see many features result in almost 0 importance. Liblinear solver successively moves only along *one* direction at a time, regularizing the others with L1 regularization (a.k.a, setting their beta to 0), which might provide a good fit for a dataset where many features are not that important in predicting the target.\n",
    "\n",
    "‚ùóÔ∏èThere is a cost to searching for the best solver. Sticking with the default (`lbfgs`) may save the most time overall, sklearn provides you this grid for an idea of which solver to choose to start off with: \n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/04-Under-the-Hood/solvers-chart.png\" width=700>\n",
    "\n",
    "\n",
    "\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  üß™ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/francoisgirard/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/francoisgirard/code/francoisgirard51/05-ML/04-Under-the-hood/data-solvers/tests\n",
      "plugins: asyncio-0.19.0, typeguard-2.13.3, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_solvers.py::TestSolvers::test_fastest_solver \u001b[32mPASSED\u001b[0m\u001b[32m                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/solvers.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed solvers step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'solvers',\n",
    "    fastest_solver=fastest_solver\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression models can also be optimized via Stochastic Gradient Descent.\n",
    "\n",
    "‚ùì Evaluate a Logistic Regression model optimized via **Stochastic Gradient Descent**. How do its precision score and training time compare to the performance of the models trained in section 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<details>\n",
    "<summary>üí° Hint</summary>\n",
    "\n",
    "- If you are stuck, look at the [SGDClassifier doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)!\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12966084480285645 0.8956957247586558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import time\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "start_time_sgd = time.time()\n",
    "sgd_model = SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "fit_time_sgd = time.time() - start_time_sgd\n",
    "\n",
    "y_pred_sgd = sgd_model.predict(X_test)\n",
    "precision_score_sgd = precision_score(y_test, y_pred_sgd, zero_division=0)\n",
    "print(fit_time_sgd, precision_score_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è The SGD model should have one of the shortest times (maybe even shorter than `liblinear`), for similar performance. This is a direct effect of performing each epoch of the Gradient Descent on a single row as opposed to loading 100k rows into memory at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Use the best model (balanced with short fit time and high precision) to predict the binary quality (0 or 1) of the following wine. Store your:\n",
    "- `predicted_class`\n",
    "- `predicted_proba_of_class` (i.e if your model predicted a class of 1 what is the probability it believes 1 to be the class should be between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.54</td>\n",
       "      <td>13.5</td>\n",
       "      <td>12.35</td>\n",
       "      <td>8.78</td>\n",
       "      <td>14.72</td>\n",
       "      <td>9.06</td>\n",
       "      <td>9.67</td>\n",
       "      <td>10.15</td>\n",
       "      <td>11.17</td>\n",
       "      <td>12.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0           9.54              13.5        12.35            8.78      14.72   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density  sulphates  alcohol  \n",
       "0                 9.06                  9.67    10.15      11.17    12.17  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_wine = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/04-Under-the-Hood/solvers_new_wine.csv')\n",
    "new_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "predicted_class = 0\n",
    "predicted_proba_of_class = 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÅ  Check your code and push your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /Users/francoisgirard/.pyenv/versions/lewagon/bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/francoisgirard/code/francoisgirard51/05-ML/04-Under-the-hood/data-solvers/tests\n",
      "plugins: asyncio-0.19.0, typeguard-2.13.3, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_new_data_prediction.py::TestNewDataPrediction::test_predicted_class \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "test_new_data_prediction.py::TestNewDataPrediction::test_predicted_proba \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/new_data_prediction.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed new_data_prediction step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'new_data_prediction',\n",
    "    predicted_class=predicted_class,\n",
    "    predicted_proba_of_class=predicted_proba_of_class\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
